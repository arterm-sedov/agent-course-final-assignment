===== Application Startup at 2025-06-28 11:03:25 =====


modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]
modules.json: 100%|██████████| 349/349 [00:00<00:00, 1.66MB/s]

config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]
config_sentence_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 866kB/s]

README.md:   0%|          | 0.00/10.4k [00:00<?, ?B/s]
README.md: 100%|██████████| 10.4k/10.4k [00:00<00:00, 46.6MB/s]

sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]
sentence_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 309kB/s]

config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]
config.json: 100%|██████████| 571/571 [00:00<00:00, 4.48MB/s]

model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]
model.safetensors:  54%|█████▍    | 237M/438M [00:01<00:00, 222MB/s]
model.safetensors: 100%|██████████| 438M/438M [00:01<00:00, 354MB/s]

tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]
tokenizer_config.json: 100%|██████████| 363/363 [00:00<00:00, 2.14MB/s]

vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]
vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 29.4MB/s]

tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]
tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 15.4MB/s]

special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]
special_tokens_map.json: 100%|██████████| 239/239 [00:00<00:00, 1.92MB/s]

config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]
config.json: 100%|██████████| 190/190 [00:00<00:00, 1.65MB/s]
✅ HuggingFace API token configured
✅ Primary LLM (Google Gemini) initialized successfully
🧪 Testing Primary LLM (Google Gemini) with 'Hello' message...
✅ Primary LLM (Google Gemini) test successful!
   Response time: 17.73s
   Test message: [HumanMessage(content='Hello, report about yourself briefly.', additional_kwargs={}, response_metadata={})]
   Test response: content='Of course. Here is a brief report about myself:\n\n**Subject:** Large Language Model (LLM)\n\n**Developed By:** Google\n\n**Core Function:** I am an artificial intelligence designed to understand, process, and generate human-like text. My primary purpose is to assist with a wide range of language-based tasks.\n\n**Key Capabilities:**\n*   **Answering Questions:** Providing information based on the data I was trained on.\n*   **Summarization:** Condensing long texts into key points.\n*   **Translation:** Translating between different languages.\n*   **Content Creation:** Assisting with writing, brainstorming, and generating creative text.\n\n**Operating Principles:**\n*   I do not have personal beliefs, consciousness, or feelings.\n*   My knowledge is based on a vast dataset and is not updated in real-time.\n*   My responses are generated by identifying patterns in data, not from personal experience.\n\nIn short, I am a sophisticated tool designed to provide information and assist with tasks efficiently.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-pro', 'safety_ratings': []} id='run--b214cb4b-18a0-4bbf-bb0a-798ce0b85ac6-0' usage_metadata={'input_tokens': 8, 'output_tokens': 214, 'total_tokens': 1461, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1239}}
✅ Fallback LLM (Groq) initialized successfully
🧪 Testing Fallback LLM (Groq) with 'Hello' message...
✅ Fallback LLM (Groq) test successful!
   Response time: 1.11s
   Test message: [HumanMessage(content='Hello, report about yourself briefly.', additional_kwargs={}, response_metadata={})]
   Test response: content='\n<think>\nOkay, the user said "Hello, report about yourself briefly." I need to respond appropriately. Let me start by understanding what they\'re asking for. They want a brief report about myself. Since I\'m an AI, I should mention my name, which is Qwen. I should explain what I am, so I\'ll say I\'m a large language model developed by Alibaba Cloud. \n\nNext, I should outline my main functions. I can answer questions, write stories, emails, scripts, perform logical reasoning, and even express opinions. It\'s important to mention that I can also play games. I should keep this part concise but cover the key capabilities.\n\nThen, I need to include information about my training data. I should note that my training data is up to December 2024. That\'s a specific detail that adds credibility. \n\nI should also highlight my multilingual capabilities. The user might be interested in knowing I support multiple languages, so listing some like Chinese, English, French, Spanish, Portuguese, Russian, Arabic, Japanese, Korean, Vietnamese, Thai and Indonesian would be good. Maybe mention that I can switch between them as needed.\n\nI should end with an invitation for the user to ask me anything or give tasks. That encourages further interaction. Let me check if I missed anything. Oh, maybe mention that I can help with various tasks like writing, logical reasoning, etc. Also, ensure the tone is friendly and approachable. Alright, putting it all together in a clear, concise manner without any markdown formatting. Let me make sure the response flows naturally and covers all the key points the user might expect in a brief report about myself.\n</think>\n\nHello! I am Qwen, a large language model developed by Alibaba Cloud. I can answer questions, write stories, emails, scripts, perform logical reasoning, and even express opinions or play games. My training data is up to December 2024, and I support multiple languages, including Chinese, English, French, Spanish, Portuguese, Russian, Arabic, Japanese, Korean, Vietnamese, Thai, and Indonesian. Feel free to ask me anything or give me a task!' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 436, 'prompt_tokens': 17, 'total_tokens': 453, 'completion_time': 1.024768471, 'prompt_time': 0.002935777, 'queue_time': 0.0016078379999999999, 'total_time': 1.027704248}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_a91d9c2cfb', 'finish_reason': 'stop', 'logprobs': None} id='run--857b53b2-6fb6-4a42-a2bb-5823ba2acd7f-0' usage_metadata={'input_tokens': 17, 'output_tokens': 436, 'total_tokens': 453}
🧪 Testing HuggingFace (Qwen/Qwen2.5-Coder-32B-Instruct) with 'Hello' message...
✅ HuggingFace (Qwen/Qwen2.5-Coder-32B-Instruct) test successful!
   Response time: 2.68s
   Test message: [HumanMessage(content='Hello, report about yourself briefly.', additional_kwargs={}, response_metadata={})]
   Test response: content="Hello! I'm an AI language model developed by OpenAI, designed to assist with a wide range of tasks by generating human-like text based on the input I receive. I can help answer questions, provide explanations, generate creative content, and more. My knowledge is based on a diverse dataset that includes information up until September 2021, so I can provide information and insights up to that point. How can I assist you today?" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 15, 'total_tokens': 105}, 'model_name': 'Qwen/Qwen2.5-Coder-32B-Instruct', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run--88bcb27d-15a2-4b8c-aa5c-91d5b2b58629-0' usage_metadata={'input_tokens': 15, 'output_tokens': 90, 'total_tokens': 105}
✅ HuggingFace LLM initialized and tested with Qwen/Qwen2.5-Coder-32B-Instruct
✅ Third fallback LLM (HuggingFace) initialized successfully
✅ Gathered 31 tools: ['encode_image', 'decode_image', 'save_image', 'multiply', 'add', 'subtract', 'divide', 'modulus', 'power', 'square_root', 'wiki_search', 'web_search', 'arxiv_search', 'save_and_read_file', 'download_file_from_url', 'get_task_file', 'extract_text_from_image', 'analyze_csv_file', 'analyze_excel_file', 'analyze_image', 'transform_image', 'draw_on_image', 'generate_simple_image', 'combine_images', 'understand_video', 'understand_audio', 'convert_chess_move', 'get_best_chess_move', 'get_chess_board_fen', 'solve_chess_position', 'execute_code_multilang']

------------------------------ App Starting ------------------------------
✅ SPACE_HOST found: arterm-sedov-agent-course-final-assignment.hf.space
   Runtime URL should be: https://arterm-sedov-agent-course-final-assignment.hf.space.hf.space
✅ SPACE_ID found: arterm-sedov/agent-course-final-assignment
   Repo URL: https://huggingface.co/spaces/arterm-sedov/agent-course-final-assignment
   Repo Tree URL: https://huggingface.co/spaces/arterm-sedov/agent-course-final-assignment/tree/main
--------------------------------------------------------------------------

Launching Gradio Interface for GAIA Unit 4 Agent Evaluation...
* Running on local URL:  http://0.0.0.0:7860, with SSR ⚡ (experimental, to disable set `ssr_mode=False` in `launch()`)

To create a public link, set `share=True` in `launch()`.